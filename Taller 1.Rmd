---
title: "Taller 1 analisis avanzado de datos"
author: "Hector Rojas"
date: "2023-03-11"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r}
library(tidyverse)
library(ggplot2)
library(Metrics)
library(palmerpenguins) 
library(scales)
library(corrplot)
install.packages("Metrics")
```

```{r}
data <- read.delim2(file="taller1.txt", header=TRUE, sep = ",", dec = ".")
head(data)
```

```{r}
modelData <- data.frame(data[,2:5001])
```


Dado el analisis anterior y debido a que este modelo tiene más variables que observaciones es una clara fuente de multicolinealidad lo que es llamado un modelo sobredefinido.

Punto 2:

```{r}
Y1 <- data$y
x <- modelData
```

Separando aleatoriamente y guardando la semilla

```{r}
set.seed(123)
train <- sample(nrow(data), nrow(data)*0.8)
x_train <- x[train, ]
y_train <- Y1[train]
x_test <- x[-train, ]
y_test <- Y1[-train]
```

```{r}
x_train <- scale(x_train)
x_test <- scale(x_test)
```

Definiendo los modelos Ridge y Lasso

```{r}
ridge <- glmnet::glmnet(x_train, y_train, alpha = 0  )
lasso <- glmnet::glmnet(x_train, y_train, alpha = 1)
```

seleccionando el valor de lambda que minimiza el ECM mediante validación cruzada

```{r}
ridge_cv <- glmnet::cv.glmnet(x_train, y_train, alpha = 0)
lasso_cv <- glmnet::cv.glmnet(x_train, y_train, alpha = 1)
```

gráfico del Mean Square Error obtenido por validación cruzada para Lasso

```{r}
plot(lasso_cv)
```

El mejor Lambda encontrado para Lasso es:

```{r}
paste("Mejor valor de lambda encontrado para Lasso:", lasso_cv$lambda.min)
paste("Mejor valor de lambda encontrado para Lasso + 1 desviación estándar:", lasso_cv$lambda.1se)
```

gráfico del Mean Square Error obtenido por validación cruzada para Ridge

```{r}
plot(ridge_cv)
```

El mejor Lambda encontrado para Ridge es:

```{r}
paste("Mejor valor de lambda encontrado para ridge:", ridge_cv$lambda.min)
paste("Mejor valor de lambda encontrado para ridge + 1 desviación estándar:", ridge_cv$lambda.1se)
```

Evolución de los coeficientes en función de lambda

```{r}
df_coeficientes_ridge <- coef(ridge) %>%
                   as.matrix() %>%
                   as_tibble(rownames = "predictor") %>%
                   rename(coeficiente_ridge = s0)

df_coeficientes_ridge %>%
  filter(predictor != "(Intercept)") %>%
  ggplot(aes(x = predictor, y = coeficiente_ridge)) +
  geom_col() +
  labs(title = "Coeficientes del modelo Ridge") +
  theme_bw() +
  theme(axis.text.x = element_text(size = 6, angle = 45))
```

Evolución de los coeficientes en función de lambda




```{r}
# Evolución de los coeficientes en función de lambda
# ==============================================================================
regularizacion <- lasso$beta %>% 
                  as.matrix() %>%
                  t() %>% 
                  as_tibble() %>%
                  mutate(lambda = lasso$lambda)

regularizacion <- regularizacion %>%
                   pivot_longer(
                     cols = !lambda, 
                     names_to = "predictor",
                     values_to = "coeficientes_lasso"
                   )

regularizacion %>%
  ggplot(aes(x = lambda, y = coeficientes_lasso, color = predictor)) +
  geom_line() +
  scale_x_log10(
    breaks = trans_breaks("log10", function(x) 10^x),
    labels = trans_format("log10", math_format(10^.x))
  ) +
  labs(title = "Coeficientes del modelo Lasso en función de la regularización") +
  theme_bw() +
  theme(legend.position = "none")
```

entrenamos nuevamente los modelos con los mejores valores de lambda encontrados

```{r}
ridge2 <- glmnet::glmnet(x_train, y_train, lambda = ridge_cv$lambda.1se, alpha = 0 )
lasso2 <- glmnet::glmnet(x_train, y_train, lambda = lasso_cv$lambda.1se,  alpha = 1)
```

```{r}
# Predicciones de entrenamiento
# ==============================================================================
predicciones_train <- predict(ridge2, newx = x_train)

# MSE de entrenamiento
# ==============================================================================
training_mse <- mean((predicciones_train - y_train)^2)
paste("Error (mse) de entrenamiento para Ridge:", training_mse)
```

```{r}
# Predicciones de test
# ==============================================================================
predicciones_test <- predict(ridge2, newx = x_test)

# MSE de test
# ==============================================================================
test_mse_ridge <- mean((predicciones_test - y_test)^2)
paste("Error (mse) de test para Ridge:", test_mse_ridge)
```

```{r}
# Predicciones de entrenamiento
# ==============================================================================
predicciones_train <- predict(lasso2, newx = x_train)

# MSE de entrenamiento
# ==============================================================================
training_mse <- mean((predicciones_train - y_train)^2)
paste("Error (mse) de entrenamiento para Lasso:", training_mse)
```

```{r}
# Predicciones de test
# ==============================================================================
predicciones_test <- predict(lasso2, newx = x_test)

# MSE de test
# ==============================================================================
test_mse_lasso <- mean((predicciones_test - y_test)^2)
paste("Error (mse) de test para Lasso:", test_mse_lasso)
```

El mejor modelo para datos de testing es Lasso ya que su ECM es mas bajo.

identificando el número óptimo de componentes del modelo Ridge:


```{r}
df_coeficientes_ridge2 <- coef(ridge2) %>%
                   as.matrix() %>%
                   as_tibble(rownames = "predictor") %>%
                   rename(coeficiente_ridge2 = s0)
df_coeficientes_ridge2 %>%
  filter(predictor != "(Intercept)") %>%
  ggplot(aes(x = predictor, y = coeficiente_ridge2)) +
  geom_col() +
  labs(title = "Coeficientes del modelo Ridge") +
  theme_bw() +
  theme(axis.text.x = element_text(size = 6, angle = 45))
```



```{r}
# Evolución de los coeficientes en función de lambda
# ==============================================================================
regularizacion2 <- lasso2$beta %>% 
                  as.matrix() %>%
                  t() %>% 
                  as_tibble() %>%
                  mutate(lambda2 = lasso2$lambda)

regularizacion2 <- regularizacion2 %>%
                   pivot_longer(
                     cols = !lambda2, 
                     names_to = "predictor",
                     values_to = "coeficientes_lasso2"
                   )

regularizacion2 %>%
  ggplot(aes(x = lambda2, y = coeficientes_lasso2, color = predictor)) 
  labs(title = "Coeficientes del modelo Lasso en función de la regularización")+
  theme(legend.position = "none")
```


```{r}
df_coeficientes_ridge2 %>%
  filter(
    predictor != "(Intercept)",
    coeficiente_ridge2 != 0
) 
```

identificando el número óptimo de componentes del modelo Lasso


```{r}
regularizacion2 %>%
  filter(
    predictor != "(Intercept)",
    coeficientes_lasso2 != 0
) 
```


```{r}
lasso_select <- glmnet::glmnet(x, Y1, lambda = lasso_cv$lambda.1se,  alpha = 1)
```

gráfico de trazas del modelo seleccionado

```{r}
plot(lasso_select, xvar = "lambda", label = TRUE)
```
calculando el ECM para el modelo con todas las obervacion es usando lasso con lambda optimo:
```{r}
x_matrix <- as.matrix(x)
pred <- predict(lasso_select, newx = x_matrix)
rmse <- Metrics::rmse(pred, Y1)
print(rmse)
```
Este error es menor a los replicados anteriormente. Luego de ejecutar los procesos y modelos a esta base de datos, encontramos que el modelo Lasso luego de la validación cruzada con el lambda optimo es el modelo que mejor ECM tiene, y a su vez este modelo mostro que solo 26 coeficientes o estimadores son suficientes para este modelo. Luego de utilizar el modelo con el lambda óptimo para todas las observaciones encontramos un ECM bajo que es menor al obtenido para las base de entrenamiento y testing.


\`\`\`
